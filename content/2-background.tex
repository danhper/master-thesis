\chapter{Background}
\section{\label{sec:code-representation} Source code representation}
The way we represent source code is very important in code clone detection,
as it affects greatly the algorithms that may be used to detect clones.k
In this section, we will explain the different ways in which source codes
can be represented.
\subsection{\label{ssec:string-representation} String representation}
The most common representation for a program is its string representation. It is
the representation that developer actually uses when editing a program, and
is therefore the easiest to obtain, as it is simply the raw program.
Listing~\ref{lis:add} is a function taking two numbers as input and returning
their sum.
\begin{lstlisting}[caption=\lstinline{add} function,label=lis:add]
int add(int a, int b) {
  return a + b;
}
\end{lstlisting}
The string representation of the above program would simply be
\begin{lstlisting}
"int add(int a, int b) {\nreturn a + b;\n}"
\end{lstlisting}
\subsection{\label{ssec:token-representation}Token representation}
While the string representation is an array of characters, the token
representation is an array of strings where each string in the array is a token
of the program. It is typically the representation that a lexer would return
while processing the source program. The above program would have the following
token representation.
\begin{lstlisting}
["int", "add", "(", "int", "a", ",", "int", "b",
 ")", "{", "return", "a", "+", "b", ";", "}"]
\end{lstlisting}
Token representation may, or may not keep whitespaces and other formatting
characters, but except for programming languages where whitespaces are significant,
such as Python, they are usually not included in the output.
\subsection{\label{ssec:tree-representation}Tree representation}
There are two main tree representations for programs: concrete syntax trees and
abstract syntax trees. We will describe the two different type of trees and
there differences.
\subsubsection{Concrete Syntax Trees}
Concrete syntax trees are concrete in the sense that they keep all the syntactic
tokens of the program, such as commas, semi-colons or parentheses. It therefore
contains exactly the same tokens as the token representation, but the tokens
are organized as a tree, where the root is usually the entry of the program,
the nodes are usually statements or expressions and the leaves are identifiers
or literals. Figure~\ref{fig:add-cst} shows how Listing~\ref{lis:add} would be
represented as a concrete syntax tree.
\begin{figure}[tb]
  \begin{center}
    \vspace*{1cm}
    \includedot[height=6cm]{./diagrams/add-cst.dot}
    \caption{\label{fig:add-cst}Concrete Syntax Tree of \lstinline{add} function}
  \end{center}
\end{figure}
\subsubsection{Abstract Syntax Trees}
Abstract Syntax Trees (AST) are also a tree representation of the source code,
but as opposed to the concrete syntax tree, they do not preserve the host
language syntax, such as parentheses, and instead express these using the
structure of the tree.
AST are typically the what a parser returns when processing the source code, and
are one of the most common representation for various tasks on programs,
including clone detection.
Figure~\ref{fig:add-ast} shows the AST for Listing~\ref{lis:add}.
\begin{figure}[tb]
  \begin{center}
    \vspace*{1cm}
    \includedot[height=6cm]{./diagrams/add-ast.dot}
    \caption{\label{fig:add-ast}Abstract Syntax Tree of \lstinline{add} function}
  \end{center}
\end{figure}
\section{Code clone fundamentals}
In this section, we will first describe the different types of code clones
that appear in the literature, and that we will be using in this thesis.
We will then view the different approaches to code clone detection that can be
found in the literature.
\subsection{Types of code clones}
It is important to define what is implied when two code fragments are
defined as clones. In the literature, code clones are usually
classified into four different types~\cite{Roy07asurvey}, from Type I to Type IV,
where Type I is the ``strongest'', meaning here that the two code fragments are
the most similar, while Type IV is the ``weakest'' --- the two code fragments
share less in common. We will now give a more precise definition of each code
clone type.
\subsubsection{Type I Clones}
Type I code clones types are clones where the code fragment are the same,
except for some variations that do not affect the logic, such as differences
in whitespaces or comments. In the literature, Type I clones are sometimes also
referred to as exact clones.
For example, let us consider the following code fragment.
\begin{lstlisting}[caption=Fibonacci function,label=lis:fibo]
int fibo(int n) {
  if (n <= 1) {
    return n;
  }
  return fibo(n - 1) + fibo(n - 2);
}
\end{lstlisting}

The following code fragment is considered to be a Type I clone.
\begin{lstlisting}
int fibo(int n) {
  if (n <= 1) { return n; } // base case of recursion
  return fibo(n-1)+
         fibo(n-2);
}
\end{lstlisting}

Although, as with the above example, line-by-line comparisons may not always
yield correct results for Type I clones, it is worth noting than if the two
fragments are pre-processed with a lexer, a simple token comparison should
normally be enough to detect this type of clones.
\subsubsection{Type II Clones}
Type II clones include the changes that can be involved in Type I clones, such
as layout and comments, but also include other changes, such as changes in
user-defined identifiers --- variable or function names. For example, the
following snippet would be a Type II clone for Listing~\ref{lis:fibo}:
\begin{lstlisting}
int fib(int x) {
  if (x <= 1) { return x; }
  return fib(x - 1) + fib(x - 2);
}
\end{lstlisting}
The function and parameter names, as well as the layout are different, but the
logic is exactly the same.
\subsubsection{Type III Clones}
Type III clones can have all the changes from type I and type II clones, but
may also have statement insertions, deletions or replacements.
Although Type III clones are usually copied from the same source code,
there is no agreement on a threshold on the number of changes to consider or not
two code fragments as type III clones. Some researchers therefore classify
type III code clones in categories such as very strong type III or weakly type
III~\cite{Sajnani:2016:SSC:2884781.2884877}.
Here is an example type III clone for Listing~\ref{lis:fibo}.
%
\begin{lstlisting}
int fib(int x) {
  int a = x;
  if (a <= 1) {
    return a;
  }
  return fib(a - 1) + fib(a - 2);
}
\end{lstlisting}

In the above code fragment, the code is completely copied from
Listing~\ref{lis:fibo}, except for a change in the identifier names, but the
second line has been inserted, making this code fragment a type III clone.
\subsubsection{Type IV Clones}
Type IV clones, also referred to as functional code clones, are two code
fragments implementing the same functionality with different approaches.
Unlike type I to III clones, type IV clones are usually not a result of
code copying, but rather of two programmers implementing the same functionality.
For example, as opposed to the recursive implementation of Fibonacci in
Listing~\ref{lis:fibo}, the following iterative implementation could be defined
to be a type IV clone.
\begin{lstlisting}[caption=Iterative Fibonacci,label=lis:iter-fibo]
int fib(int n) {
  int a = 0, b = 1;
  for (int i = 0; i < n; i++) {
    int tmp = a + b;
    a = b;
    b = tmp;
  }
  return a;
}
\end{lstlisting}
The two code fragments will return the same result for any $n \geq 0$ and are
therefore functional clones. Although the implemented functionality
is the same, there are no other common point in the implementations.
Furthermore, Listing~\ref{lis:fibo} and Listing~\ref{lis:iter-fibo} clearly
have different time complexities, but to the best of our knowledge, there
are no established convention to whether this kind of complexity changes
should be taken into account when deciding if two code fragments are, or not,
type IV code clones. In this thesis, we will therefore assume that as long
as two code fragments implement same functionality, they are type IV clones.
\subsection{Approaches to clone detection}
There exist various methods to clone detection, which take advantage of the
different source code representations described in
section~\ref{sec:code-representation}. We will present the major
approaches found in the literature.
\subsubsection{Text-based detection}
Text-based clone detection are based on the string representation of the program
source code described in~\ref{ssec:string-representation}.
While some text-based techniques use the source code almost as is and perform
either line-by-line or global string comparisons to find clones, some techniques
do apply some preprocessing steps \cite{Baker92aprogram}, such as removing white
spaces, before actually passing the source code to a string matching algorithm.
\subsubsection{Token-based detection}
Token-based detection techniques use the token representation of the program
described in~\ref{ssec:token-representation}. Token-based approach are usually
more robust to formatting and layout changes compared to text-based approaches.
Some token-based clone detection tools, such as CCFinder
\cite{Kamiya:2002:CMT:636188.636191} first normalize the tokens and replace all
application specific tokens such as user-defined identifiers. On the other hand,
other tools such as SourcererCC \cite{Sajnani:2016:SSC:2884781.2884877} keep
this information and use it to detect if multiple code fragments are clones or
not.
\subsubsection{Tree-based detection}
Tree-based techniques make use of the AST representation of the program
described in \ref{ssec:tree-representation}. These techniques first use a parser
to generate the AST of a program, then the ASTs are searched for similar
sub-trees and similar sub-trees are marked as clones. Searching for similar
sub-trees using normal tree comparisons algorithms takes at least
$\mathcal{O}\left(n^3\right)$ \cite{Baxter:1998:CDU:850947.853341}, where $n$ is
the number of nodes. Industrial software can have millions of line of codes, and
therefore $n$ could be in the order of 10 million. To avoid this issue, many
tree-based clone detection techniques \cite{Baxter:1998:CDU:850947.853341,
  Jiang:2007:DSA:1248820.1248843} use hash functions on sub-tress to find clones
more efficiently. The idea is to assign each sub-tree a hash-value, and use this
value, usually with bucketing techniques, to quickly search for code clones.
\section{Machine learning fundamentals}
In this section, we will present the basics of machine learning that will be
needed in order to understand our approach. We will first give a general
overview of the learning process of neural networks, then we will describe
the two models we are using as a base to our work in this thesis.
The first model will present is the skipgram model, which is typically used in
natural language processing (NLP) to assign a vector representation to a word.
Next, we will give an overview of recurrent neural networks (RNN), and in
particular long-short term memory (LSTM) networks, which are extensively used in
NLP to assign a vector representation to a sentence.
\subsection{Neural networks}
In this subsection, we will show how are neural network composed, and what is
the normal process to train them. Although most of what we explain here apply to
most machine learning algorithms, we will focus on feed-forward neural networks.
\subsubsection{Computations of a neural network}
A neural network \cite{Rojas:1996:NNS:235222} is usually composed of an input
layer, which is where the input data is fed, one or more hidden layers, and an
output layer, which represents the value outputted by the neural network.
Each layer in the network is composed by units, also sometimes referred to as
neurons, which are the computing elements of the network. Each unit is usually
composed of two different parts: a first function $f$, which reduces a vector
into a single scalar value, and a function $g$, called ``activation function''
which transforms the result of $f$ and produces the unit output. This function
is generally non-linear, otherwise the model ends up to be composed of only
linear function and becomes as well a linear function.
A unit of a neural network is illustrated in figure \ref{fig:neuron}.
\begin{figure}[tb]
  \centering\input{diagrams/nn-unit}
  \caption{\label{fig:neuron}Unit of a neural network}
\end{figure}
Each layer is connected to the next one by using the output of each unit of the
previous layer as an input for each unit of the next layer. This connection is
illustrated in figure \ref{fig:neural-net}.
\begin{figure}[tb]
  \centering\input{diagrams/neural-net}
  \caption{\label{fig:neural-net}Neural network}
\end{figure}

The function $f$ is a matrix multiplication where all the weights of this matrix
are parameters of the neural network model. Matrix weights are shared by all the
units in a layer. In figure \ref{fig:neural-net}, given $W^{(1)} \in
\mathbb{R}^{5\times 3}$ is the matrix weights of the hidden layer, $W_{mn}$ is
the value at row $m$ and column $n$ in this matrix, $g_1$ is the activation
function of the hidden layer, and $a_1, a_2$ and $a_3$ the output of each unit
in the layer, we will have the following.
\begin{align*}
  a_1 &= g\left( W_{11}^{(1)}x_1 + \cdots + W_{51}^{(1)}x_5 \right)\\
  a_2 &= g\left( W_{12}^{(1)}x_1 + \cdots + W_{52}^{(1)}x_5 \right)\\
  a_3 &= g\left(W_{13}^{(1)}x_1 + \cdots + W_{53}^{(1)}x_5 \right)
\end{align*}
In practice, given $x = (x_1, \cdots, x_5)$ and $a = (a_1, a_2, a_3)$, the above
is usually computed as follow, with a single matrix multiplication and a
vectorized implementation of the function $g$.

\[ a = g\left(  x W^{(1)}  \right) \]

Finally, given $W^{(2)} \in \mathbb{R}^{3\times 1}$ the weights of the output
layer and $g_2$ the activation of the output layer, the output $\hat{y}$ of the neural
network will be computed as follow.

\begin{equation}
  \hat{y} = g_2\left( g_1\left( x W^{(1)} \right) W^{(2)} \right)
\end{equation}
\subsubsection{Training of a neural network}
Training a neural network is searching for the optimal weights to approximate
the function the neural network should learn. In the above example, this process
consists in searching values for $W^{(1)}$ and $W^{(2)}$.
The ``optimal'' weights of a neural network are defined with respect to a loss
function representing how far the neural network output is from the expected
correct answer, which is chosen depending on the task. Some common loss
functions include mean squared error (MSE) \ref{eq:mse} or cross-entropy
error (CEE) \ref{eq:cee}. Given a set of outputs $\hat{Y} = \{ \hat{y_1}, \cdots,
\hat{y_n} \}$ and their respective expected values $Y = \{ y_1, \cdots,
y_n \}$, the errors are defined as follow.

\begin{align}
  \label{eq:mse}MSE(\hat{Y}, Y) &= \frac{1}{n}\sum_{i=1}^{n} \left( y_i - \hat{y_i} \right)^2\\
  \label{eq:cee}CEE(\hat{Y}, Y) &= \frac{1}{n}\sum_{i=1}^{n}
                                  y_i\log\hat{y_i} + (1 - y_i)\log(1 - \hat{y_i})
\end{align}
Mean squared error is typically used when there is an order relation between the
possible outputs while cross-entropy error is mostly used for classification
tasks where the output can either be correct or incorrect.

The most common way to update the weights of the neural network is called the
back propagation algorithm, and consists in computing the derivatives of the
loss function with respect to the weights of the model using the derivative
chain rule, and to use these to update the weights with optimization methods
such as the gradient descent. For example, given a loss function $L(W)$, to
update $W^{(2)}$ in the above network, we would compute the error derivative
$\partial L(W)/\partial W^{(2)}$, multiply the result with a learning
rate $\alpha$, which is a hyper parameter of the model, and subtract the result
from the current value of $W^{(2)}$. This process is usually repeated until the
error converges.
\subsubsection{Evaluating a model}
When training a neural network, or any kind of machine learning algorithm, we
need a way to know if the model produces the results we expect or not --- a way
to evaluate the quality of the model. The error, also called loss, we presented
above can be an indicator of how well a performing but it is unfortunately not
easy to interpret as depending on the used function the range can vary largely
and it is difficult to significantly compare the values produced by different
errors functions. We therefore tend to use measures other than the loss to
evaluate the quality of the model. We will present different measures that
are commonly used. We will only present measures used for binary classification
here, but all of these measures can be generalized in some way to also work for
multi-class classification.

To define the different measure we will use, we will first introduce the notions
of true positive, false positive, true negative and false negative.

\begin{description}
\item[True positive] A sample predicted as true and was actually true
\item[False positive] A sample predicted as true but was actually false
\item[True negative] A sample predicted as false and was actually false
\item[False negative] A sample predicted as false but was actually true
\end{description}

We will assume we have a set of predicted samples $S$ with $|S| > 0$, and we
will note the set of true positives as $T_p$, false positives as $F_p$, true
negatives as $T_n$ and false negatives as $F_n$.

One of the most common and simplest measure to understand is the accuracy of a
model. The accuracy is, as shown in equation~\ref{eq:accuracy} the number of
samples correctly predicted divided by the total number of samples predicted.

\begin{equation}
  \label{eq:accuracy}
  \text{accuracy} = \frac{|T_p| + |T_n|}{|S|}
\end{equation}

The accuracy has a range of $[0, 1]$, and a higher accuracy is better.
It is widely used to evaluate a model, but may have shortcomings depending on
the dataset. A common issue with the accuracy measure is with unbalanced
datasets --- a dataset with much more negative samples than positive samples, or
vice-versa. For example, given a dataset with 99\% of negative samples, if a
model returns a negative result for any sample, it will achieve 99\% accuracy
but will not be useful at all.

To be able to get a better understanding of a model performance, especially when
the dataset is unbalanced, the precision and recall measures are often used. The
precision of a model, given by equation~\ref{eq:precision} is the ratio of
samples correctly predicted to the total number of samples that have been
evaluated as positive.

\begin{equation}
  \label{eq:precision}
  \text{precision} = P = \frac{|T_p|}{|T_p| + |F_p|}
\end{equation}

The precision also has a range of $[0, 1]$, with $1$ being the best achievable
precision, meaning that all samples predicted as positives were actually
positives. However, the precision by itself may not be enough: if a model
predicts a single sample as positive, and the sample actually turns out to be
positive, the precision will be $1$ but the model might be missing a lot of
other positive samples. This is why the recall measure is also often used. The
recall measure, given by equation~\ref{eq:recall}, is the ratio of correctly
predicted samples to the total number of positive samples.

\begin{equation}
  \label{eq:recall}
  \text{recall} = R = \frac{|T_p|}{|T_p| + |F_n|}
\end{equation}

The precision also has a range of $[0, 1]$, and $1$ is also being the best
achievable recall. If a model predicts all samples to false, as in the example
we gave for the accuracy, the recall will therefore be $0$, as obviously there
will be no sample in the true positives set. However, the recall by itself is
not enough, as predicting all samples to be positive would be enough to achieve
a recall of $1$. The recall and precision are therefore usually used together.
To avoid having to look at two different measures when evaluating a model, the
F1-score --- which is the harmonic mean of the recall and the precision as shown
in equation~\ref{eq:f1-score} --- is often used.
\begin{equation}
  \label{eq:f1-score}
  \text{F1-score} = \dfrac{2}{\frac{1}{P} + \frac{1}{R}} = 2\frac{P\cdot R}{P + R}
\end{equation}

As the F1-score is the harmonic mean of two measures with a range of $[0, 1]$,
it also has the same range, and as for the precision and recall, a higher
F1-score means that the model is performing better.
The main reason for using a harmonic mean instead of arithmetic mean is that it
allows to penalize the score if one of the value is much lower than the other,
therefore forcing both the recall and the precision to be high in order to have
a high score.
\subsection{\label{ssec:skipgram-model}Skipgram model}
As mentioned above, skipgram is used to assign a vector in $\mathbb{R}^d$, known
as a word embedding, to a word, where $d$ is the number of dimensions wanted for
each word vector. This algorithm has first been presented in 2013 by Mikolov \&
al.~\cite{DBLP:journals/corr/MikolovSCCD13} and is now used in many natural
language processing tasks as one of the word2vec algorithms.

To understand the motivations behind this algorithm, and other algorithms used
to learn word embeddings, we must first understand how words used to be
represented in natural language processing tasks. The most common approach was
to use a finite vocabulary of size $|V|$, and to assign an identifier to each
word in this vocabulary. For example, the word ``network'' could have the id
$123$, and would be represented as a vector in ${\{0,1\}}^{|V|}$ where only index
$123$ of the vector would be $1$ and all the other indexes would be $0$. This
approach has two disadvantages: each word is represented by a very large and
sparse vector, and the representation of each word do not have any semantic
properties, so ``network'' and ``networks'' vector representations would not be
any closer than ``network'' and any other word representation.

The motivation behind skipgram is to address this issue by encoding each word
as a vector in $\mathbb{R}^d$ where $d$ is not dependent of $|V|$, in such a way
that each word embedding has some semantic so that, for example, similar words
have a smaller distance in $\mathbb{R}^d$ than unrelated words.

We will now describe how the skipgram algorithm actually computes the vector
embeddings for each word. The algorithm works in an unsupervised fashion and
usually uses a large amount of text written in the language of the vocabulary.
For each sentence, a set of training samples composed of a ``context'' word and
a ``target'' word. The context word is a word in the sentence, while the target
word is a word around the context word, which is distant by at most a predefined
window size. For example, if the window size is 2, and we have the following
sentence,
\begin{quotation}
the quick brown fox jumped over the lazy dog
\end{quotation}
the target words for the context word ``fox'' will be ``quick'', ``brown'',
``jumped'' and ``over''. These samples are used to train a neural network with a
single hidden layer. The word embeddings are the hidden layer of the network and
have dimension $\mathbb{R}^{|V|\times d}$. The network is trained by using the context
word index to select a vector from the hidden layer weight and using a
cross-entropy error function so that when the word is a target, the label should
be $1$ and $0$ otherwise. Also this could be done by using a softmax output,
this would require to compute softmax on all the vocabulary, which can be
extremely large. To reduce the computation cost, a common approach is to used
negative sampling. The negative sampling approach only computes the output for
the target word, as well as a predetermined number of noise word --- word
not in the window of the context --- and uses the sum of these errors to train
the model.
\subsection{\label{ssec:rnn}Recurrent Neural Networks}
While word embeddings work well to represent a single word, and to model the
similarities between words, it is not enough to encode a whole sentence. There
are many approaches to encode a sentence into a vector, and Recurrent Neural
Networks (RNN) is one of them. The main idea of RNNs is to reuse the previous
output as an input, as shown in \ref{fig:rnn}.
\begin{figure}[tb]
  \begin{center}
    \includegraphics[width=8cm]{./images/rnn.pdf}
    \caption{\label{fig:rnn}Unrolled Recurrent Neural Network}
  \end{center}
\end{figure}
Typically, each $x_t$ is a word in the sentence, encoded either as a
one-hot vector or as a word embedding. In its simplest form, a RNN will compute
its output using equation \ref{eq:rnn}, where $W$, $U$ and $b$ are parameters of
the model. The parameters are shared across all time steps.
\begin{equation}
  h_t = \tanh\left( W x_t + U h_{t - 1} + b \right) \label{eq:rnn}
\end{equation}
Although this models seems promising, it suffers a major issue --- it is very
difficult to capture long-term dependencies because of the vanishing gradients
issue~\cite{pascanu2013difficulty}. When computing the gradients to
back-propagate the error through the network, the gradient for $\partial x_t$
with respect to $\partial x_k$, used in the chain rule, can be expanded as
follow.
\begin{equation}
  \frac{\partial x_t}{\partial x_k} = \prod_{t \geq i > k} \frac{\partial x_i}{\partial x_{i-1}}
  \label{eq:rnn-vanishing-gradients}
\end{equation}
The term $\partial x_i/\partial x_{i-1}$ in equation~%
\ref{eq:rnn-vanishing-gradients} is less then $1$~\cite{pascanu2013difficulty},
which means that the value will converge to $0$, and error will not propagate
all the way through the network, hence the vanishing gradient issue.

To overcome this issue, Long Short-Term Memory (LSTM) networks~%
\cite{Hochreiter:1997:LSM:1246443.1246450} are often used instead of vanilla RNN
described above. Instead of equation~\ref{eq:rnn}, LSTMs use equations~%
\ref{eq:lstm-1} to~\ref{eq:lstm-6} to compute the output value. All $W$, $U$ and
$b$ in the equations are parameters of the model.
\begin{align}
  f_t &= \sigma \left( W^{(f)}x_t + U^{(f)}h_{t - 1} + b^{(f)} \right) \label{eq:lstm-1}\\
  i_t &= \sigma \left( W^{(i)}x_t + U^{(i)}h_{t - 1} + b^{(i)} \right)\\
  u_t &= \tanh \left( W^{(u)}x_t + U^{(u)}h_{t - 1} + b^{(u)} \right)\\
  o_t &= \sigma \left( W^{(o)}x_t + U^{(o)}h_{t - 1} + b^{(o)} \right)\\
  c_t &= i_t \odot u_t + f_t \odot c_{t - 1}\\
  h_t &= o_t \odot \tanh(c_t) \label{eq:lstm-6}
\end{align}
In the above equations, $\sigma$ is the sigmoid function defined by equation
\ref{eq:sigmoid},
\begin{equation}
  \label{eq:sigmoid}
  \sigma(x) = \frac{1}{1 + e^{-x}}
\end{equation}
and the different values have the following meaning.
\begin{description}
\item[$f_t$] --- forget gate --- how much of the previous state should be used
\item[$i_t$] --- input gate --- how much of the input should be used
\item[$u_t$] --- update gate --- the value of the current input
\item[$o_t$] --- output gate --- how much of the current result should be outputted
\item[$c_t$] --- memory cell --- the state of the network
\item[$h_t$] --- hidden layer --- the output of the LSTM cell
\end{description}
Given $g^n(x_t, h_{t-1}) = W^{(n)}x_t + U^{(n)} h_{t-1} + b^{(n)}$, figure~%
\ref{fig:lstm-cell} shows how the inputs flow in equations~\ref{eq:lstm-1} to~%
\ref{eq:lstm-6} to generate the outputs of an LSTM cell.
\begin{figure}[tb]
  \begin{center}
    \includegraphics[width=14cm]{./images/lstm-cell.png}
    \caption{\label{fig:lstm-cell}LSTM cell}
  \end{center}
\end{figure}
In an LSTM network, the state is not passed through $h_t$ as with a plain RNN,
but through $c_t$, called the memory cell. Due to the additive nature of $c_t$,
the error will also be propagated in an additive manner when computing the
derivative for $c_t$~\cite{Hochreiter:1997:LSM:1246443.1246450}, avoiding the
vanishing gradient problem encountered when using plain RNNs.
%
\section{\label{sec:motivating-exmaple}Motivating example}
With the proliferation of programming languages, a single project or application
is often written using multiple programming languages. For example, a project
having a native client for the web, Android and iOS will most likely have at
least a part of it written in JavaScript, a part written in Java or Kotlin and
another part written in Swift or Objective C. A common issue with such a project
is having a large amount of logic duplicated for each client. In many cases,
business logic for an application with multiple frontends can be extracted to
the backend to avoid duplication. This issue is difficult to tackle from both an
organizational point of view as well as a technical point of view.
From the organizational point of view, a common project development structure
would have a project manager making high level and mostly non-technical
decisions, while a team would be assigned for each component of the project, for
example a team would work on the backend API, a team on the Android application,
another team on the iOS application and finally a team on the web client.
Although thorough discussion between the team can help to mitigate code
duplication on the client side up to a certain point, it remains a very tedious
issue to track.

As an example, we will present a simplified version of a case we actually
encountered while building a web service. The frontend user interface, shown in
figure~\ref{fig:app-messages-screen}, consists of a page displaying recent
messages grouped by sender.

\begin{figure}[tb]
  \centering\includegraphics[width=6cm]{./images/app-messages-screen.pdf}
  \caption{\label{fig:app-messages-screen} Study case application user interface}
\end{figure}

As the conversation grouping feature was not part of the initial application,
and has been added later on, the API would simply have an HTTP endpoint
\lstinline{GET /messages} returning a list of the user messages. Given this
restriction on the API side, the frontend clients need to group the messages by
conversation, leading to duplicated code show in
listings~\ref{lis:group-messages-js},~\ref{lis:group-messages-swift}
and~\ref{lis:group-messages-java}. All of these listings implement the
following piece of functionality
\begin{enumerate}
\item Sort messages from the oldest to the newest
\item Group messages by the ID of the sender
\item Sort each group from the oldest to the newest based on its newest message
\item Return the result as a collection of collections of messages
\end{enumerate}
%
\begin{figure}
  \lstinputlisting[
    language=JavaScript,basicstyle=\ttfamily\footnotesize,
    label=lis:group-messages-js,caption=Message grouping logic in JavaScript]
    {./snippets/group-sort.js}
\end{figure}
%
\begin{figure}
  \lstinputlisting[
    language=Java,basicstyle=\ttfamily\footnotesize,
    label=lis:group-messages-java,caption=Message grouping logic in Java]
    {./snippets/GroupSort.java}
\end{figure}
%
\begin{figure}
  \lstinputlisting[
    language=Swift,basicstyle=\ttfamily\footnotesize,
    label=lis:group-messages-swift,caption=Message grouping logic in Swift]
    {./snippets/GroupSort.swift}
\end{figure}
%
Listing~\ref{lis:group-messages-js} is implemented in JavaScript,
listing~\ref{lis:group-messages-java} is implemented in Java and
listing~\ref{lis:group-messages-js} is implemented in Swift which are
respectively used for the web client, the Android application and the iOS
application. Although the logic is implemented in exactly the same way, each
language have its particularities and there are therefore some differences in
the implementation of each snippet. It is also worth noting that there are also
semantic differences in the different implementations that can be more tedious
to notice at first look.
The first step in all the implementations is to sort the list of messages
received as an argument. All three implementations use some \lstinline{sort}
implementation available in the standard library of each language, but this
creates an important semantic difference --- Swift implementation does not
modify the argument, while Java and JavaScript implementation modifies it. This
side effect can be particularly difficult to notice in the JavaScript
implementation as the return value of the \lstinline{sort} method is used, and
it is not clear that the function argument is actually modified without having
to search the documentation. The next step of the implementation is to group all
the messages by their \lstinline{senderId}. This makes use of a
\lstinline{map}-like data structure, which is available as a builtin of all
three languages. All snippets loop over all the messages, maps the
\lstinline{senderId} key to an empty list if it does not already exist, and adds
the current message to the \lstinline{senderId} list. All the grouped messages
are then collected in a list of list, using the map \lstinline{values} function
when available, or looping through the map otherwise. Finally, the list of list
is sorted using the \lstinline{sentAt} value of its last message, using the
\lstinline{last} method if available and indexing otherwise. These snippets are
therefore very similar, and a decent programmer could immediately tell that they
are implementing exactly the same functionality, but they contain enough
differences so that a simple token or tree-level comparison fail to actually
detect the similarity.

Although we have focused our example on frontend clients, this issue is also
very common with any kind of system where multiple actors consume a same source
of information. For example, microservice architecture, where a service can be
consumed by a multitude of other services, may also run into the same kind of
issue.
\section{\label{sec:related-work}Related work}
Many clone detection systems, such as CCFinder~%
\cite{Kamiya:2002:CMT:636188.636191}, DECKARD~%
\cite{Jiang:2007:DSA:1248820.1248843} or SourcererCC~%
\cite{Sajnani:2016:SSC:2884781.2884877} support multiple languages but are
mostly designed to find clones within the same programming languages and not
across them. Some other recent research use
deep learning approach for clone detection such
as~\cite{ijcai2017-423}
or~\cite{DBLP:journals/corr/abs-1710-06159} use deep learning approaches to
detect clones within a single programming language, but do not discuss the
possibility to extend their method to detecting clones across programming
languages. Other approaches such as~\cite{White:2016:DLC:2970276.2970326} can
work across languages but focus on classifying programs, rather than on
detecting code clones.
Token-based clone detection tools such as
SourcererCC~\cite{Sajnani:2016:SSC:2884781.2884877} are very efficient
to find clones which are introduced by copy-pasting, as these sort of clones
are copy-pasted source code share many tokens, but less efficient when clones
are introduced by replication of a same functionality by two different entities.
When working across programming languages, the chances of two code snippets
sharing a large amount of tokens is further reduced, making token comparisons
based approaches less likely to detect clones.
For example, when comparing listing~\ref{lis:group-messages-js} and listing
~\ref{lis:group-messages-swift}, line 2 of both listings declare a map-like
data structure in order to group messages by sender id. However, this is
impossible to infer with simple token comparisons, and would need some encoding
about the data types and how they relate to each other to be possible. Some
systems such as~\cite{kraft2008cross}, which are designed to detect clones
between programming languages, mitigate this issue by converting the
source code to a common AST format, but assumes that the two input languages
have a common intermediate representation, in this case both target the .NET
platform.
A slightly more complicated example is the implementation of the sort function
at line 14 in listing~\ref{lis:group-messages-js} and line 11 in
listing~\ref{lis:group-messages-swift}. In listing~\ref{lis:group-messages-js},
the access to the last element of the array is done using
\lstinline{a[a.length - 1]}, while in listing~\ref{lis:group-messages-swift},
the same operation is done by using \lstinline{a.last!}. Although an experienced
developer would have no trouble identifying the fact that both codes implement
the same functionality, there is currently, to the best of our knowledge, no
system capable of detecting such similarities in a completely unsupervised
fashion. Finally, an even harder similarity to detect is between lines 10 to 13
in listing~\ref{lis:group-messages-js} and the first method call of line 10 in
listing~\ref{lis:group-messages-swift}. The purpose of both codes are to get all
the values of the map data structure previously created in the form of a list or
an array, but although this can be done using the \lstinline{values} property of
the dictionary data structure in Swift, there is no builtin method on the
JavaScript object and the same operation therefore requires to loop over its
elements. This is an example of a type IV code clone, which up to now no system
has managed to detect very accurately --- all systems presented here report a
recall score close to $0$ for type IV clones --- and the difference between the
languages make this task even harder. However, to find interesting results
given the motivating example above, this is one of the types of code clones that
we would like to become able to detect.
